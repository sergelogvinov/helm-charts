# Default values for postgresql-single.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: postgres
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

## PostgreSQL admin user
## ref: https://hub.docker.com/_/postgres
postgresqlUsername: postgres

## PostgreSQL password
## ref: https://hub.docker.com/_/postgres
##
# postgresqlPassword:

## Create a database
## ref: https://hub.docker.com/_/postgres
##
# postgresqlDatabase:

# postgresqlConfiguration:
# postgresqlConfigurationLogs:

# postgresqlConninfo: host=postgres user=postgres

pgHbaConfiguration: |-
  # host  database    user                  address       auth-method
  #
  local   all         all                                 trust
  local   replication postgres                            trust
  host    all         all                   localhost     trust
  host    postgres    postgres              10.0.0.0/8    md5
  hostssl postgres    postgres              10.0.0.0/8    md5
  host    replication postgres              10.0.0.0/8    md5
  hostssl replication postgres              10.0.0.0/8    md5

tlsCerts:
  create: false

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podlabels: {}

podAnnotations: {}

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 999
  runAsGroup: 999
  fsGroup: 999
  fsGroupChangePolicy: "OnRootMismatch"

priorityClassName: ~

terminationGracePeriodSeconds: 120

securityContext:
  seccompProfile:
    type: RuntimeDefault
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL

service:
  type: ClusterIP
  port: 5432

postgresqlServerMemory: "128"
resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi

# extraVolumes:
#   - name: gcp-certs
#     secret:
#       defaultMode: 420
#       secretName: backup-gcp
# extraVolumeMounts:
#   - name: gcp-certs
#     mountPath: /etc/gcp
#     readOnly: true

persistence:
  enabled: false
  ## A manually managed Persistent Volume and Claim
  ## If defined, PVC must be created manually before volume will be bound
  # existingClaim:
  mountPath: /database
  # storageClass: "-"
  accessModes:
    - ReadWriteOnce
  size: 8Gi
  annotations: {}

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

## updateStrategy for PostgreSQL StatefulSet and its slaves StatefulSets
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy:
  type: RollingUpdate

backup:
  enabled: false
  recovery: false

  image:
    repository: koehn/postgres-wal-g
    pullPolicy: IfNotPresent
    tag: 12.4-v0.2.15-2

  walpush: false
  walg: ~

  cleanPolicy: "retain FULL 3"

  # set value "" to disable cron backup
  schedule: "15 4 * * *"

  resources:
    limits:
      cpu: 2
      memory: 1Gi
    requests:
      cpu: 1500m
      memory: 512Mi

backupCheck:
  enabled: false
  schedule: "15 8 * * *"

  resources:
    limits:
      cpu: 2
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 512Mi

  persistence:
    ## A manually managed Persistent Volume and Claim
    # existingClaim:
    #
    # storageClass: "-"
    accessModes:
      - ReadWriteOnce
    size: 8Gi
    annotations: {}

  nodeSelector: {}

  tolerations: []

  affinity: {}

metrics:
  enabled: false
  image:
    repository: quay.io/prometheuscommunity/postgres-exporter
    pullPolicy: IfNotPresent
    tag: v0.9.0

  database: postgres
  username: postgres

  queries: |-
    pg_replication:
      query: "SELECT CASE WHEN NOT pg_is_in_recovery() THEN 0 ELSE GREATEST (0, EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))) END AS lag"
      master: true
      metrics:
        - lag:
            usage: "GAUGE"
            description: "Replication lag behind master in seconds"
    pg_postmaster:
      query: "SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()"
      master: true
      metrics:
        - start_time_seconds:
            usage: "GAUGE"
            description: "Time at which postmaster started"
    pg_database:
      query: "SELECT pg_database.datname, pg_database_size(pg_database.datname) as size_bytes FROM pg_database"
      master: true
      cache_seconds: 30
      metrics:
        - datname:
            usage: "LABEL"
            description: "Name of the database"
        - size_bytes:
            usage: "GAUGE"
            description: "Disk space used by the database"
    # pg_stat_user_tables:
    #   query: |
    #    SELECT
    #      current_database() datname,
    #      schemaname,
    #      relname,
    #      seq_scan,
    #      seq_tup_read,
    #      idx_scan,
    #      idx_tup_fetch,
    #      n_tup_ins,
    #      n_tup_upd,
    #      n_tup_del,
    #      n_tup_hot_upd,
    #      n_live_tup,
    #      n_dead_tup,
    #      n_mod_since_analyze,
    #      COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,
    #      COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,
    #      COALESCE(last_analyze, '1970-01-01Z') as last_analyze,
    #      COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,
    #      vacuum_count,
    #      autovacuum_count,
    #      analyze_count,
    #      autoanalyze_count
    #    FROM
    #      pg_stat_user_tables
    #   metrics:
    #     - datname:
    #         usage: "LABEL"
    #         description: "Name of current database"
    #     - schemaname:
    #         usage: "LABEL"
    #         description: "Name of the schema that this table is in"
    #     - relname:
    #         usage: "LABEL"
    #         description: "Name of this table"
    #     - seq_scan:
    #         usage: "COUNTER"
    #         description: "Number of sequential scans initiated on this table"
    #     - seq_tup_read:
    #         usage: "COUNTER"
    #         description: "Number of live rows fetched by sequential scans"
    #     - idx_scan:
    #         usage: "COUNTER"
    #         description: "Number of index scans initiated on this table"
    #     - idx_tup_fetch:
    #         usage: "COUNTER"
    #         description: "Number of live rows fetched by index scans"
    #     - n_tup_ins:
    #         usage: "COUNTER"
    #         description: "Number of rows inserted"
    #     - n_tup_upd:
    #         usage: "COUNTER"
    #         description: "Number of rows updated"
    #     - n_tup_del:
    #         usage: "COUNTER"
    #         description: "Number of rows deleted"
    #     - n_tup_hot_upd:
    #         usage: "COUNTER"
    #         description: "Number of rows HOT updated (i.e., with no separate index update required)"
    #     - n_live_tup:
    #         usage: "GAUGE"
    #         description: "Estimated number of live rows"
    #     - n_dead_tup:
    #         usage: "GAUGE"
    #         description: "Estimated number of dead rows"
    #     - n_mod_since_analyze:
    #         usage: "GAUGE"
    #         description: "Estimated number of rows changed since last analyze"
    #     - last_vacuum:
    #         usage: "GAUGE"
    #         description: "Last time at which this table was manually vacuumed (not counting VACUUM FULL)"
    #     - last_autovacuum:
    #         usage: "GAUGE"
    #         description: "Last time at which this table was vacuumed by the autovacuum daemon"
    #     - last_analyze:
    #         usage: "GAUGE"
    #         description: "Last time at which this table was manually analyzed"
    #     - last_autoanalyze:
    #         usage: "GAUGE"
    #         description: "Last time at which this table was analyzed by the autovacuum daemon"
    #     - vacuum_count:
    #         usage: "COUNTER"
    #         description: "Number of times this table has been manually vacuumed (not counting VACUUM FULL)"
    #     - autovacuum_count:
    #         usage: "COUNTER"
    #         description: "Number of times this table has been vacuumed by the autovacuum daemon"
    #     - analyze_count:
    #         usage: "COUNTER"
    #         description: "Number of times this table has been manually analyzed"
    #     - autoanalyze_count:
    #         usage: "COUNTER"
    #         description: "Number of times this table has been analyzed by the autovacuum daemon"
    # pg_statio_user_tables:
    #   query: "SELECT current_database() datname, schemaname, relname, heap_blks_read, heap_blks_hit, idx_blks_read, idx_blks_hit, toast_blks_read, toast_blks_hit, tidx_blks_read, tidx_blks_hit FROM pg_statio_user_tables"
    #   metrics:
    #     - datname:
    #         usage: "LABEL"
    #         description: "Name of current database"
    #     - schemaname:
    #         usage: "LABEL"
    #         description: "Name of the schema that this table is in"
    #     - relname:
    #         usage: "LABEL"
    #         description: "Name of this table"
    #     - heap_blks_read:
    #         usage: "COUNTER"
    #         description: "Number of disk blocks read from this table"
    #     - heap_blks_hit:
    #         usage: "COUNTER"
    #         description: "Number of buffer hits in this table"
    #     - idx_blks_read:
    #         usage: "COUNTER"
    #         description: "Number of disk blocks read from all indexes on this table"
    #     - idx_blks_hit:
    #         usage: "COUNTER"
    #         description: "Number of buffer hits in all indexes on this table"
    #     - toast_blks_read:
    #         usage: "COUNTER"
    #         description: "Number of disk blocks read from this table's TOAST table (if any)"
    #     - toast_blks_hit:
    #         usage: "COUNTER"
    #         description: "Number of buffer hits in this table's TOAST table (if any)"
    #     - tidx_blks_read:
    #         usage: "COUNTER"
    #         description: "Number of disk blocks read from this table's TOAST table indexes (if any)"
    #     - tidx_blks_hit:
    #         usage: "COUNTER"
    #         description: "Number of buffer hits in this table's TOAST table indexes (if any)"
    pg_stat_slow_queries:
      query: SELECT pg_get_userbyid(userid) as rolname,t3.datname,queryid,calls,max_time / 1000 as max_time_seconds,REGEXP_REPLACE(substring(query,1,100),'["\n\s]','','g') as sql FROM pg_stat_statements t1 JOIN pg_database t3 ON (t1.dbid=t3.oid) WHERE rows != 0 AND max_time > 1000 ORDER BY max_time DESC LIMIT 10
      metrics:
        - rolname:
            usage: "LABEL"
            description: "Name of user"
        - datname:
            usage: "LABEL"
            description: "Name of database"
        - queryid:
            usage: "LABEL"
            description: "Query ID"
        - sql:
            usage: "LABEL"
            description: "SQL"
        - calls:
            usage: "COUNTER"
            description: "Number of times executed"
        - max_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent in the statement, in milliseconds"
    pg_stat_activity_idle:
      query: |
        WITH
          metrics AS (
            SELECT
              application_name,
              SUM(EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change))::bigint)::float AS process_seconds_sum,
              COUNT(*) AS process_seconds_count
            FROM pg_stat_activity
            WHERE state = 'idle'
            GROUP BY application_name
          ),
          buckets AS (
            SELECT
              application_name,
              le,
              SUM(
                CASE WHEN EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change)) <= le
                  THEN 1
                  ELSE 0
                END
              )::bigint AS bucket
            FROM
              pg_stat_activity,
              UNNEST(ARRAY[1, 2, 5, 15, 30, 60, 90, 120, 300]) AS le
            GROUP BY application_name, le
            ORDER BY application_name, le
          )
        SELECT
          application_name,
          process_seconds_sum,
          process_seconds_count,
          ARRAY_AGG(le) AS process_seconds,
          ARRAY_AGG(bucket) AS process_seconds_bucket
        FROM metrics JOIN buckets USING (application_name)
        GROUP BY 1, 2, 3
      metrics:
        - application_name:
            usage: "LABEL"
            description: "Application Name"
        - process_seconds:
            usage: "HISTOGRAM"
            description: "Idle time of server processes"

  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 10m
      memory: 32Mi

nodeSelector: {}

tolerations: []

affinity: {}
